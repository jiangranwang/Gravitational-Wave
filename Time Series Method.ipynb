{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "from scipy import spatial\n",
    "from glob import glob\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_dirs = 2\n",
    "dirs = glob('../fma_small/*')\n",
    "dirs = dirs[:num_dirs]\n",
    "dirs = [str(dirs[i]) + str('/*.mp3') for i in range(len(dirs))]\n",
    "dirs = [glob(dirs[i]) for i in range(len(dirs))]\n",
    "path = []\n",
    "for i in range(len(dirs)):\n",
    "    path += dirs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100\n",
    "LENGTH = int(1.5*Fs)\n",
    "INPUT_LEN = 30*Fs\n",
    "INTERVAL = int(0.05*Fs) #in seconds, determines how many fingerprints each song will generate\n",
    "\n",
    "def get_batch(path, k=None, shuffle=True):\n",
    "    ## path: path that contains the label of the music\n",
    "    ## k: batch size\n",
    "\n",
    "    batch = []\n",
    "    label = []\n",
    "    \n",
    "    music = [AudioSegment.from_file(files) for files in path]\n",
    "    \n",
    "    for i in range(len(music)):\n",
    "        temp = np.array(music[i].get_array_of_samples())\n",
    "        # check if the audio has two channels\n",
    "        if len(temp) > INPUT_LEN: \n",
    "            temp = [temp[i] for i in range(0,len(temp),2)] #get left channel only\n",
    "            \n",
    "        # convert to fingerprints\n",
    "        num_fp = int((len(temp)-LENGTH)/INTERVAL)+1\n",
    "        for j in range(num_fp):\n",
    "            segment = temp[j*INTERVAL:j*INTERVAL+LENGTH]\n",
    "            segment = np.asarray(segment)          \n",
    "            batch.append(segment)\n",
    "        \n",
    "        # discard last few elements\n",
    "        # create label for the current music (modify so that only nearby segment have the same label)\n",
    "        label += [int(path[0][17:23])] * num_fp\n",
    "        print('num music: '+str(i))\n",
    "\n",
    "    batch = np.asarray(batch)\n",
    "    label = np.asarray(label)\n",
    "\n",
    "    # shuffle all samples\n",
    "    if shuffle:\n",
    "        s = np.arange(batch.shape[0])\n",
    "        np.random.shuffle(s)\n",
    "        batch = batch[s]\n",
    "        label = label[s]\n",
    "    \n",
    "    # create k-size batches\n",
    "    if k != None:\n",
    "        num_batch = int(batch.shape[0]/k)\n",
    "        batch = batch[:num_batch*k]\n",
    "        label = label[:num_batch*k]\n",
    "        batch = batch.reshape(num_batch, k, LENGTH, 1)\n",
    "        label = label.reshape(num_batch, k)\n",
    "        batch = [batch[i]/np.amax(batch[i]) for i in range(batch.shape[0])]\n",
    "        \n",
    "    # normalize data\n",
    "    batch = np.asarray(batch)\n",
    "    label = np.asarray(label)\n",
    "    batch = batch.astype(np.float32)\n",
    "    batch = batch/np.amax(batch)\n",
    "\n",
    "    return np.asarray(batch), np.asarray(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num music: 0\n",
      "time taken: 0:00:04.809125\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "train_data, train_label = get_batch(path[:1])\n",
    "end = datetime.datetime.now()\n",
    "print('time taken: '+str(end-start)) #4s without gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN = 0.2\n",
    "\n",
    "# helper function for triplet loss\n",
    "def dist(x,y):\n",
    "    diffs = tf.expand_dims(x, axis=1) - tf.expand_dims(y, axis=0)\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(diffs), axis=-1))\n",
    "\n",
    "def triplet_loss(dists, labels):\n",
    "    identity_mask = tf.equal(tf.expand_dims(labels, axis=1),\n",
    "                             tf.expand_dims(labels, axis=0))\n",
    "    negative_mask = tf.logical_not(identity_mask)\n",
    "    positive_mask = tf.logical_xor(identity_mask,\n",
    "                                   tf.eye(tf.shape(labels)[0], dtype=tf.bool))\n",
    "\n",
    "    furthest_positive = tf.reduce_max(dists*tf.cast(positive_mask, tf.float32), axis=1)\n",
    "    closest_negative = tf.map_fn(lambda x: tf.reduce_min(tf.boolean_mask(x[0], x[1])),\n",
    "                                (dists, negative_mask), tf.float32)\n",
    "    \n",
    "    diff = furthest_positive - closest_negative\n",
    "    \n",
    "    return tf.maximum(diff + MARGIN, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = 64\n",
    "SPLIT = 8\n",
    "\n",
    "def model(features):\n",
    "    # convolution layer 1 \n",
    "    conv1 = tf.layers.conv1d(\n",
    "        inputs=features,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 1\n",
    "    pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2)\n",
    "    \n",
    "    # convolution layer 2 \n",
    "    conv2 = tf.layers.conv1d(\n",
    "        inputs=pool1,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 2\n",
    "    pool2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2)\n",
    "    \n",
    "    # convolution layer 3 \n",
    "    conv3 = tf.layers.conv1d(\n",
    "        inputs=pool2,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 3\n",
    "    pool3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2)\n",
    "    \n",
    "    # convolution layer 4 \n",
    "    conv4 = tf.layers.conv1d(\n",
    "        inputs=pool3,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 4\n",
    "    pool4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2)\n",
    "    \n",
    "    # convolution layer 3 \n",
    "    conv5 = tf.layers.conv1d(\n",
    "        inputs=pool4,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 3\n",
    "    pool5 = tf.layers.max_pooling1d(inputs=conv5, pool_size=2, strides=2)\n",
    "    \n",
    "    # convolution layer 3 \n",
    "    conv6 = tf.layers.conv1d(\n",
    "        inputs=pool5,\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling layer 3\n",
    "    pool6 = tf.layers.max_pooling1d(inputs=conv6, pool_size=2, strides=2)\n",
    "\n",
    "    ### more convolution layers here...\n",
    "\n",
    "    # flatten input: 16*64=1024\n",
    "    flat = tf.layers.flatten(pool6)\n",
    "\n",
    "    # divide and encode\n",
    "    concatenate = []\n",
    "    num_each_split = flat.shape[-1]//SPLIT\n",
    "    units = NUM_EMBEDDING//SPLIT\n",
    "    splits = tf.split(flat, SPLIT, 1)\n",
    "\n",
    "    for i in range(SPLIT):\n",
    "        divide = tf.layers.dense(splits[i], activation=tf.nn.relu, units=128)\n",
    "        divide = tf.layers.dense(divide, activation=tf.nn.relu, units=units)\n",
    "        concatenate.append(divide)\n",
    "    \n",
    "    embedding = tf.concat([elem for elem in concatenate], 1)\n",
    "    # final embedding\n",
    "    #embedding = tf.layers.dense(flat,\n",
    "                                #activation=None,\n",
    "                                #kernel_initializer=tf.truncated_normal_initializer,\n",
    "                                #units=NUM_EMBEDDING)\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling1d_12/Squeeze:0\", shape=(?, 33075, 32), dtype=float32)\n",
      "Tensor(\"max_pooling1d_13/Squeeze:0\", shape=(?, 16537, 32), dtype=float32)\n",
      "Tensor(\"max_pooling1d_14/Squeeze:0\", shape=(?, 8268, 32), dtype=float32)\n",
      "Tensor(\"max_pooling1d_15/Squeeze:0\", shape=(?, 4134, 32), dtype=float32)\n",
      "Tensor(\"max_pooling1d_16/Squeeze:0\", shape=(?, 2067, 32), dtype=float32)\n",
      "Tensor(\"max_pooling1d_17/Squeeze:0\", shape=(?, 1033, 32), dtype=float32)\n",
      "Tensor(\"flatten_3/Reshape:0\", shape=(?, 33056), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.placeholder(tf.float32, [None, LENGTH, 1])\n",
    "input_label = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# loss function operations\n",
    "embedded = model(input_data)\n",
    "dists = dist(embedded, embedded)\n",
    "loss = tf.reduce_mean(triplet_loss(dists, input_label))\n",
    "\n",
    "# train operation\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(\n",
    "    loss=loss,\n",
    "    global_step=tf.train.get_global_step())\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../fma_small/132/132791.mp3', '../fma_small/132/132118.mp3', '../fma_small/132/132568.mp3', '../fma_small/132/132456.mp3', '../fma_small/135/135337.mp3', '../fma_small/135/135341.mp3', '../fma_small/132/132773.mp3', '../fma_small/132/132787.mp3', '../fma_small/135/135371.mp3', '../fma_small/132/132965.mp3', '../fma_small/132/132794.mp3', '../fma_small/135/135336.mp3']\n",
      "num music: 0\n",
      "num music: 1\n",
      "num music: 2\n",
      "num music: 3\n",
      "num music: 4\n",
      "num music: 5\n",
      "num music: 6\n",
      "num music: 7\n",
      "num music: 8\n",
      "num music: 9\n",
      "num music: 10\n",
      "num music: 11\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "num_path = 8\n",
    "path_per_itr = len(path)//num_path\n",
    "batch_size = 128\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_hist = []\n",
    "    \n",
    "for i in range(num_epoch):\n",
    "    # shuffle the path\n",
    "    np.random.shuffle(path)\n",
    "    for j in range(num_path):\n",
    "        cur_path = path[path_per_itr*j:path_per_itr*(j+1)]\n",
    "        print(cur_path)\n",
    "        train_data, train_label = get_batch(cur_path, batch_size)\n",
    "        for k in range(train_data.shape[0]):\n",
    "            _, loss_val = sess.run([train_op, loss],\n",
    "                                    feed_dict={input_data: train_data[k],\n",
    "                                               input_label: train_label[k]})\n",
    "            loss_hist.append(loss_val)\n",
    "            print('batch num: '+str(k))\n",
    "        print('iter num: '+str(j))\n",
    "    print('num_epoch: '+str(i)+' loss: '+str(loss_hist[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
